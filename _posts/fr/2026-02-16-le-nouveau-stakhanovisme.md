---
layout: post
title: "Le nouveau stakhanovisme"
date: 2026-02-16
categories: [ai, work, philosophy, organization, series]
excerpt: 'Le mouvement stakhanoviste célébrait des ouvriers modèles pour relever les quotas de tous les autres. Les entreprises AI-native rejouent le même scénario.'
header_image: "https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Stakhanov.JPG/1600px-Stakhanov.JPG"
header_image_alt: "Alexeï Stakhanov, mineur de charbon soviétique et héros du mouvement stakhanoviste"
header_image_credit: "Soviet Archives"
header_image_credit_url: "https://commons.wikimedia.org/wiki/File:Stakhanov.JPG"
header_image_source: "Wikimedia Commons"
header_image_source_url: "https://commons.wikimedia.org"
ref: the-new-stakhanovism
redirect_from:
  - /2026/02/09/le-nouveau-stakhanovisme/
  - /fr/2026/02/09/le-nouveau-stakhanovisme/
lang: fr
---

Alexeï Stakhanov était mineur. Lazar Jovanovic est vibe codeur. Quatre-vingt-dix ans les séparent, mais la mécanique est la même : un ouvrier modèle, une infrastructure invisible et des quotas qui montent pour tout le monde.

## La fable

En 1935, Alexeï Stakhanov extrait 102 tonnes de charbon en un seul poste, soit 14 fois la norme. L'Union soviétique en fait un héros, et le mouvement stakhanoviste naît. Des ouvriers modèles dépassent les quotas pour prouver que le système fonctionne.

Ce que la propagande ne mentionne pas, ce sont les équipes qui lui dégagent le terrain, préparent ses outils et retirent les obstacles. Il n'est pas seul, il est *mis en scène*.

Cette mise en scène sert deux objectifs : légitimer le système, et relever les quotas pour tous les autres. « Si Stakhanov y arrive, pourquoi pas toi ? »

En juin 2025, Elena Verna, Head of Growth chez Lovable, publie [The Rise of the AI-Native Employee](https://www.elenaverna.com/p/the-rise-of-the-ai-native-employee). Elle y décrit un modèle radical : des petites équipes sans process ni handoff, pas de middle management et l'IA comme outil par défaut. Construire plutôt que coordonner, avec 35 personnes pour 80 millions de dollars d'ARR. Le #AINativeEmployeeEra.

Huit mois plus tard, Lovable met Lazar Jovanovic sur [le podcast de Lenny](https://www.lennysnewsletter.com/p/getting-paid-to-vibe-code), le plus grand podcast produit de la tech. C'est leur « premier vibe codeur professionnel » : il n'a aucune formation académique et livre des produits en production en utilisant uniquement l'IA. Lazar n'est pas ingénieur, c'est la thèse faite chair.

Pendant ce temps, Lovable affiche des dizaines de postes ouverts, dont Recruitment Coordinator, Customer Success Manager et Enterprise Account Executive. Ce sont exactement les rôles de coordination et de middle management qu'Elena décrivait comme condamnés.

Derrière les démos de Lazar, il y a des platform engineers, des spécialistes sécurité et des account executives expérimentés. Mais la fable retient une seule chose : si lui peut le faire, pourquoi pas toi ?

Lovable est le cas le plus visible d'un schéma plus large. Amazon a [supprimé 18 000 postes](https://www.npr.org/2023/01/04/1147034858/amazon-ceo-says-company-will-layoff-more-than-18-000-workers) aux États-Unis. Klarna a annoncé que [son assistant IA faisait le travail de 700 agents](https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/). Duolingo a [coupé ses contractuels](https://techcrunch.com/2024/01/09/duolingo-cut-10-of-its-contractor-workforce-as-the-company-embraces-ai/) après avoir étendu ses capacités IA et l'a présenté comme une évolution naturelle. La fable est toujours la même : le système fonctionne, et l'humain est optionnel. Les discussions sur Hacker News ([Amazon](https://news.ycombinator.com/item?id=34427277), [Klarna](https://news.ycombinator.com/item?id=39531662) et [Duolingo](https://news.ycombinator.com/item?id=38918279)) sont parfois plus révélatrices que les communiqués eux-mêmes.

Ça ne réfute pas la thèse, un SaaS comparable à ce stade emploierait peut-être un millier de personnes, et Lovable construit peut-être réellement un modèle plus léger. Mais quand l'effectif réel d'une entreprise s'éloigne autant du récit qu'elle projette, on ne décrit plus l'avenir, on le met en scène.

Et le parallèle n'est évidemment pas politique, personne n'a fini au goulag. Il est *narratif* : un ouvrier modèle rendu visible, une infrastructure rendue invisible et une norme imposée à tous les autres.

## Le zèle

Mais la fable ne fonctionne que si on oublie ce qu'elle comprime. Et ce qui se comprime en premier, c'est la nature même du travail humain.

Prenons un ouvrier sur une chaîne d'assemblage automobile. Il doit visser un boulon dans un filetage. Le boulon ne rentre pas. Il en essaie un deuxième, puis un troisième, aucun ne passe. La procédure dit d'arrêter la chaîne. Mais arrêter la chaîne coûte des dizaines de milliers d'euros par minute. Alors il court chercher un seau d'huile, trempe les boulons dedans et les force un par un. La chaîne ne s'arrête pas. Le produit sort, personne ne sait.

Cet ouvrier, cet écart entre la procédure et le geste, c'est ça le [travail vivant](/fr/2026/01/01/la-triche-qui-fait-tourner-le-monde/). Non pas l'obéissance à l'instruction mais la loyauté envers le résultat. C'est le zèle productif, celui qui dit : je sais ce qu'on m'a demandé, mais voilà ce qu'il faut vraiment faire.

Il en existe un autre : la réunion inutile convoquée par loyauté envers le process, le contournement politique, la code review rituelle que personne ne lit vraiment et le [rapport hebdomadaire qui finit dans le vide](/fr/2026/01/23/le-test-de-la-tarte-aux-pommes/). C'est le zèle parasitaire, la dévotion au rituel du travail plutôt qu'à sa substance.

Un agent IA supprime les deux dans le même geste. Il n'a pas de corps, pas de friction avec le réel. Il ne trempe rien dans l'huile, il ne *triche* pas, mais il ne convoque pas non plus de réunions inutiles. Depuis l'intérieur d'un system prompt, les deux déviances se ressemblent.

« Pas de process, pas de handoff, juste construire » est la [grève du zèle](/fr/2026/01/01/la-triche-qui-fait-tourner-le-monde/) de l'IA, non pas l'obéissance pour ralentir mais l'obéissance pour accélérer. Dans les deux cas, l'espace où le jugement humain corrige l'écart entre l'instruction et la réalité se comprime.

## La compression

Quand l'espace du jugement se comprime, c'est la norme qui monte. Le mouvement stakhanoviste servait une fonction économique précise : si Stakhanov pouvait faire 14 fois la norme, la norme pouvait monter. Chaque ouvrier était mesuré à l'aune du modèle, et la productivité n'était pas redistribuée, elle était *extraite*.

Le récit AI-native reprend la même logique. Quand une entreprise démontre qu'une personne avec l'IA peut faire le travail de quatre, la question n'est pas de produire quatre fois plus, c'est de savoir pourquoi on paie encore les trois autres. L'ouvrier modèle passe sur un podcast, et ceux dont les rôles sont devenus « redondants » mettent à jour leur LinkedIn en silence.

C'est la logique du [stack ranking](https://en.wikipedia.org/wiki/Vitality_curve) appliquée non plus par un manager lors de l'évaluation annuelle mais par un passage sur un podcast. Celui qui utilise l'IA efficacement devient la référence. Chacun développe sa propre martingale, son propre setup pour produire au-delà de ce que le rythme d'avant permettait, et les attentes montent. À un moment, il faudra choisir : le nouveau Stakhanov sera préféré à l'autre. Le travailleur modèle recalibre la norme pour tous les autres.

Dans ce contexte, Lazar pose la question jusqu'au bout. Il n'a aucune formation académique. Si on le prend au sérieux, quel est encore l'argument pour l'ingénieur diplômé qui empile des architectures de plus en plus complexes ?

## Ce qui reste ouvert

Le stakhanovisme original a fini par s'effondrer sous le poids de ses propres quotas. Le zèle productif (le boulon dans l'huile, l'écart qui sauve le produit et le jugement qu'aucun system prompt ne peut encoder) ne peut pas être automatisé, seulement écrasé.

Reste la question que personne ne pose. Quelqu'un doit bien décider ce que l'agent sait, ce qu'il ignore et où il s'arrête. Ce quelqu'un configure les limites d'un agent IA avec lequel chaque employé interagit quotidiennement et décide de ce qui est pensable. Ce rôle n'a pas de nom, pas de gouvernance et pas de trace d'audit. Appelons ça, en écho à Hannah Arendt, la banalité de la configuration. C'est [une question de pouvoir, pas de technique](/fr/2026/02/18/qui-ecrit-la-constitution-des-machines/).
